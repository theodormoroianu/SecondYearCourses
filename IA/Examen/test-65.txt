1. In cazul algoritmului de coborare pe gradient:
A. Actualizam ponderile cu minus valoarea gradientului
B. Actualizam ponderile cu valoarea ratei de invatare
C. Actualizam ponderile cu valoarea gradientului
D. Ponderile nu se actualizeaza in acest algoritm

2. Care este scufundarea asociata functiei nucleu Hellinger?
A. f(x) = x
B. Nu exista
C. f(x) = sqrt(x)
D. k(x,y) = <sqrt(x), sqrt(y)>, unde <,> denote produsul scalar

daca pp ca suntem in 2 dimensiuni:
phi(x1, x2) = (sqrt(x1), sqrt(x2)) 
<phi(x1,x2), phi(z1,z2)> = 
	= <(sqrt(x1), sqrt(x2)), (sqrt(z1), sqrt(z2))> =
	= sqrt(x1 * z1) + sqrt(x2 * z2)
=> raspunsul e C - daca sqrt de un vector e component wise.


3. Putem prefera sa utilizam functia de neliniaritate ReLU in comparatie cu Tanh deoarece:
A. Gradientii se satureaza doar pe partea negativa
B. Are mereu rezultate mai bune
C. Este conceputa special pentru probleme de regresie
D. Este derivabila in fiecare punct

4. Urmatoarele functii cost sunt specifice regresiei:
A. MSE si IoU
B. Cross-Entropy si IoU
C. MAE si MSE
D. MAE si Cross-Entropy

5. Ce dimensiune spatiala va avea un activation map dupa aplicarea unui strat convolutional cu 8 filtre de 5x5 cu stride=1 pe o intrare de 32x32x3, fara bordare?
A. 32x32x1
B. 32x32x8
C. 28x28x8
D. 28x28x1

6. Presupunerea algoritmului Naive Bayes este ca:
A. Multimea de trasaturi are un numar minim de elemente
B. Trasaturile sunt independente
C. Multimea de trasaturi are un numar maxim de elemente
D. Trasaturile sunt liniar dependente

7. Care din urmatoarele functii de activare aduce output-ul in intervalul (0, 1)?
A. Sigmoida
B. Leaky ReLU
C. ELU
D. Tangenta Hiperbolica

8. Care este scufundarea asociata functiei nucleu liniare?
A. k(x,y) = <x,y>, unde <,> denote produsul scalar
B. Nu exista
C. f(x) = x
D. f(x) = sqrt(x)
=> C

9. Care este iesirea unei retele neuronale cu 3 unitati ascunse si o unitate de iesire cu activari de tip ReLU pentru intrarea x = [1, 2], daca ponderile sunt W1 = [-0.5, 3, -2; 2, -1, 0], B1 = [0, 1, -1], W2 = [-1; 3; 2], B2 = [2]?
A. 4.5
B. 0
C. 2
D. 6

10. Care afirmatie este adevarata pentru un niste date normalizate cu scalarea standard?
A. Deviatia standard a datelor este aproximativ 1
B. Valorile datelor sunt intre 0 si 1
C. Valorile datelor sunt intre -1 si 1
D. Scalarea standard nu functioneaza pentru date negative
