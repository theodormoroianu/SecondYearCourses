1. Care este scufundarea asociata functie nucleu RBF?
A. k(x,y) = exp(- d(x,y) / (2 * sigma)), unde d(x,y) denote distanta Euclidiana
B. Nu exista
C. f(x) = x
D. f(x) = sqrt(x)


2. Pentru punctele [(2,2),(1,2),(1,1),(2,1)], avand etichetele [0,1,1,0], care este eticheta punctului (2,2) utilizand metoda 3-NN?
A. Este necesar un criteriu suplimentar pentru departajarea claselor.
B. 0 in cazul in care C <= 1, 1 altfel
C. 0
D. 1


9. Care este forma duala utilizand kernel-ul liniar pe matricea X, daca forma primala este X = [[0.5, 2.7, 3], [4, 1.5, 6]]?
A. X_dual = [[16.54, 24.05], [24.55, 4.25]]
B. X_dual = [[16.14, -24.05], [24.05, 59.25]]
C. X_dual = [[16.54, 24.05], [24.05, 54.25]]
D. X_dual = [[16.54, -2.05], [25.05, 54.25]]


1. In cazul analizei liniar discriminante, hiperplanul pe care se proiecteaza punctele este:
A. Paralel cu hiperplanul de separare, distanta fiind controlata prin bias
B. Orienta astfel incat punctele sa fie cat mai departate
C. Orientat astfel incat punctele sa fie cat mai apropriate
D. Perpendicular pe hiperplanul de separare



4. Invatarea nusupervizata presupune ca setul de antrenare este compus din:
A. Etichete
B. Date si model invatare
C. Date
D. Date si etichete



6. Care din urmatoarele metode este folosita pentru a combate bias-ul modelului?
A. F1-score
B. Alegerea unui model mai complex
C. Reducerea numarului de exemple
D. Early stopping

3. Cati clasificatori binari trebuie antrenati pentru a rezolva o problema cu K clase folosind metoda One vs One?
A. 2 * K + 1
B. K / 2
C. (K * (K - 1)) / 2
D. K - 1


7. Care este matricea de confuzie a unui clasificator, pentru setul de test cu etichetele 
[1,2,3,1,1,2,2,1,3,2] si predictiile 
[2,1,3,1,1,1,1,2,2,2]?
A. [[2 2 0],[3 1 0],[0 1 1]]
B. [[2 0 0],[1 4 1],[0 1 1]]
C. [[2 3 0],[2 1 1],[0 0 1]]
D. [[1 2 0],[0 3 0],[1 0 3]]

8. Care este cel mai probabil efect pe care il putem obtine pentru modelul de regresie ridge cand setam parametrul de regularizare alpha cu o valoarea foarte mica?
A. Putem face overfitting
B. Model se comporta ca un model de regresie liniara
C. Modelul nu este influentat
D. Modelul ramane constant

9. Care este scufundarea asociata functie nucleu liniare?
A. Nu exista
B. f(x) = x
C. k(x,y) = <x,y>, unde <,> denote produsul scalar
D. f(x) = sqrt(x)

3. Daca valoarea functiei cost este aproximativ la fel pentru setul de testare cat si pentru cel de antrenare, cel mai probabil:
A. Este in regim de overfitting
B. Este in regim de underfitting
C. Este in regin optim de antrenare
D. Nici una dintre variante


5. Care este forma duala utilizand kernel-ul liniar pe exemplul de test X_test = [-0.5, 0.4, -0.5], daca X_train = [[-0.3, 2, 0.3], [-1, -2.6, -4], [0.5, -1, -0.5], [-3, -4, -2.7]]? X_train si X_test sunt in forma primala.
A. X_test_dual = [0.8, 1.46, -0.4]
B. X_test_dual = [-1.2, -2.46, 1.4, 1.25]
C. X_test_dual = [-0.8, -1.46, 0.4, 1.25]
D. X_test_dual = [0.8, 1.46, -0.4, 1.25]

7. Care sunt valorile urmatoarelor exemple de antrenare si testare dupa ce se aplica normalizarea standard (standardizarea), X_train = [[10, 5, 3], [-1, -2, -30], [-0.5, 0.5, 0.3]], X_test = [[0.5, -1, 7], [1.2, 3.4, 5.6]]?
A. X_train = [[-1.41, -1.32, -0.79], [-0.75, -1.09, -1.41], [-0.65, -0.23, 0.61]]; X_test = [[-0.46, -0.74, 1.06], [-0.32, 0.77, 0.96]]
B. X_train = [[1.41, 1.32], [-0.75, -1.09], [-0.65, -0.23]]; X_test = [[-0.46, -0.74, 1.06], [-0.32, 0.77, 0.96]]
C. X_train = [[1.41, 1.32, 0.79], [-0.75, -1.09, -1.41], [-0.65, -0.23, 0.61]]; X_test = [[0.46, 0.74, -1.06], [-0.32, 0.77, 0.96]]
D. X_train = [[1.41, 1.32, 0.79], [-0.75, -1.09, -1.41], [-0.65, -0.23, 0.61]]; X_test = [[-0.46, -0.74, 1.06], [-0.32, 0.77, 0.96]]

10. Care din urmatoarele functii este potrivita pentru masurarea performantei unui clasificator aplicat pe date cu distrubutie balansata?
A. Logistic loss
B. Acuratetea
C. Media intrarilor in valoare absoluta
D. Media patratelor erorilor

1. In cazul algoritmului de coborare pe gradient:
A. Actualizam ponderile cu minus valoarea gradientului
B. Actualizam ponderile cu valoarea ratei de invatare
C. Actualizam ponderile cu valoarea gradientului
D. Ponderile nu se actualizeaza in acest algoritm


2. Care este scufundarea asociata functiei nucleu Hellinger?
A. f(x) = x
B. Nu exista
C. f(x) = sqrt(x)
D. k(x,y) = <sqrt(x), sqrt(y)>, unde <,> denote produsul scalar

3. Putem prefera sa utilizam functia de neliniaritate ReLU in comparatie cu Tanh deoarece:
A. Gradientii se satureaza doar pe partea negativa
B. Are mereu rezultate mai bune
C. Este conceputa special pentru probleme de regresie
D. Este derivabila in fiecare punct

8. Care este scufundarea asociata functiei nucleu liniare?
A. k(x,y) = <x,y>, unde <,> denote produsul scalar
B. Nu exista
C. f(x) = x
D. f(x) = sqrt(x)

4. Care ditre aceste optiuni pot sa ajute in imbunatatirea capacitatii de generalizare a unui model de invatare automata?
A. Oprirea invatarii atunci cand eroarea pe setul de validare incepe sa creasca
B. Cresterea numarului de epoci de invatare
C. Micsorarea setului de antrenare
D. Cresterea numarului de parametri antrenabili ai modelului.

5. Ce tip de metrica poate obtine 100% acuratete pe datele de antrenare pentru urmatorul set de puncte 2D [([3, 3], 1), ([5, 8], 0), ([5, 5], 0), ([2, 2], 1), ([0, 1], 1), ([5, 9], 0)] considerand un clasificator KNN cu un singur vecin?
A. Cosinus
B. L1
C. L2
D. Niciunul dintre raspunsuri